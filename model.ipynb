{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56b50db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 recommendations for User 1:\n",
      "Movie ID: 1, Estimated Rating: 1\n",
      "Movie ID: 2, Estimated Rating: 1\n",
      "Movie ID: 3, Estimated Rating: 1\n",
      "Movie ID: 4, Estimated Rating: 1\n",
      "Movie ID: 5, Estimated Rating: 1\n"
     ]
    }
   ],
   "source": [
    "#using Matrix Factorization-based Algorithm\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, LabelEncoder\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "from surprise import SVD\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "\n",
    "\n",
    "# HANDLE OUTLIRS FUNCTION\n",
    "def handle_outliers(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    df = df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "    return df\n",
    "\n",
    "\n",
    "# MOVIES DATASET &  RATINGS DATASET\n",
    "movies_df = pd.read_csv(r\"C:\\Users\\nh013\\Desktop\\movie recommendation system dataset\\movies.csv\")\n",
    "ratings_df = pd.read_csv(r\"C:\\Users\\nh013\\Desktop\\movie recommendation system dataset\\ratings.csv\")\n",
    "\n",
    "\n",
    "\n",
    "# MOVIES DATAFRAME FEATURE EXTRACT\n",
    "movies_df = movies_df[['movieId', 'title', 'genres']]\n",
    "\n",
    "# FEATURE EXTRACT RATING DATAFRAME \n",
    "ratings_df = ratings_df[['userId', 'movieId', 'rating', 'timestamp']]\n",
    "\n",
    "\n",
    "\n",
    "# CHECK MISSING VALUES\n",
    "movies_df.dropna(inplace=True)\n",
    "ratings_df.dropna(inplace=True)\n",
    "\n",
    "# HANDLE OUTLIERS\n",
    "movies_df = handle_outliers(movies_df, 'movieId')\n",
    "ratings_df = handle_outliers(ratings_df, 'rating')\n",
    "\n",
    "\n",
    "\n",
    "# CONVERT CATEGORICAL VALUES TO NUMERICAL TO MOVIES DATAFRAME \n",
    "categorical_cols_movies = ['title', 'genres']\n",
    "for col in categorical_cols_movies:\n",
    "    movies_df[col] = movies_df[col].astype('category').cat.codes\n",
    "\n",
    "# CONVERT CATEGORICAL VALUES TO NUMERICAL TO RATING DATAFRAME\n",
    "categorical_cols_ratings = ['userId']\n",
    "for col in categorical_cols_ratings:\n",
    "    ratings_df[col] = ratings_df[col].astype('category').cat.codes\n",
    "\n",
    "    \n",
    "    \n",
    "# LETS CREATE A SURPRISE DATASET FROM RATING_DF\n",
    "reader = Reader(rating_scale=(-1, 1))\n",
    "data = Dataset.load_from_df(ratings_df[['userId', 'movieId', 'rating']], reader)\n",
    "\n",
    "\n",
    "#SVD ALGORITHM\n",
    "algo = SVD()\n",
    "\n",
    "# TRAIN THE MODEL\n",
    "trainset = data.build_full_trainset()\n",
    "algo.fit(trainset)\n",
    "\n",
    "# GET TOP n RECOMMENDATION FOR USERS\n",
    "user_id = 1\n",
    "n = 5\n",
    "\n",
    "user_predictions = []\n",
    "for movie_id in movies_df['movieId'].unique():\n",
    "    pred = algo.predict(str(user_id), str(movie_id))\n",
    "    user_predictions.append(pred)\n",
    "\n",
    "# SHORT PREDICTION BY ESTIMATE RATING\n",
    "user_predictions.sort(key=lambda x: x.est, reverse=True)\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Top {n} recommendations for User {user_id}:\")\n",
    "for pred in user_predictions[:n]:\n",
    "    movie_id = pred.iid\n",
    "    estimated_rating = pred.est\n",
    "    print(f\"Movie ID: {movie_id}, Estimated Rating: {estimated_rating}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2bb008",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4b4990",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640bf621",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8286b78a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 recommendations for User 1 using Surprise SVD:\n",
      "Movie ID: 1, Estimated Rating: 1\n",
      "Movie ID: 2, Estimated Rating: 1\n",
      "Movie ID: 3, Estimated Rating: 1\n",
      "Movie ID: 4, Estimated Rating: 1\n",
      "Movie ID: 5, Estimated Rating: 1\n",
      "XGBoost RMSE: 0.8727472217117144\n"
     ]
    }
   ],
   "source": [
    "# using XGBOOST model ...........\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, LabelEncoder\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "from surprise import SVD\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "\n",
    "from surprise.model_selection import cross_validate\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# HANDLE OUTLIER FUNCTION\n",
    "def handle_outliers(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    df = df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "# MOVIES DATASET & RATINGS DATASET\n",
    "movies_df = pd.read_csv(r\"C:\\Users\\nh013\\Desktop\\movie recommendation system dataset\\movies.csv\")\n",
    "ratings_df = pd.read_csv(r\"C:\\Users\\nh013\\Desktop\\movie recommendation system dataset\\ratings.csv\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# MOVIES DATAFRAME FEATURE EXTRACT\n",
    "movies_df = movies_df[['movieId', 'title', 'genres']]\n",
    "\n",
    "# FEATURE EXTRACT RATING DATAFRAME \n",
    "ratings_df = ratings_df[['userId', 'movieId', 'rating', 'timestamp']]\n",
    "\n",
    "\n",
    "\n",
    "# CHECK MISSING VALUES\n",
    "movies_df.dropna(inplace=True)\n",
    "ratings_df.dropna(inplace=True)\n",
    "\n",
    "\n",
    "# HANDLE OUTLIERS\n",
    "movies_df = handle_outliers(movies_df, 'movieId')\n",
    "ratings_df = handle_outliers(ratings_df, 'rating')\n",
    "\n",
    "\n",
    "\n",
    "# CONVERT CATEGORICAL VALUES TO NUMERICAL TO MOVIES DATAFRAME \n",
    "categorical_cols_movies = ['title', 'genres']\n",
    "for col in categorical_cols_movies:\n",
    "    movies_df[col] = movies_df[col].astype('category').cat.codes\n",
    "\n",
    "# CONVERT CATEGORICAL VALUES TO NUMERICAL TO RATING DATAFRAME\n",
    "categorical_cols_ratings = ['userId']\n",
    "for col in categorical_cols_ratings:\n",
    "    ratings_df[col] = ratings_df[col].astype('category').cat.codes\n",
    "\n",
    "    \n",
    "    \n",
    "# SURPRISE DATASET FROM RATING_DF\n",
    "reader = Reader(rating_scale=(-1, 1))\n",
    "data = Dataset.load_from_df(ratings_df[['userId', 'movieId', 'rating']], reader)\n",
    "\n",
    "# SVD ALGORITHM FROM SURPRISE\n",
    "algo = SVD()\n",
    "\n",
    "# TRAIN SVD MODEL\n",
    "trainset = data.build_full_trainset()\n",
    "algo.fit(trainset)\n",
    "\n",
    "# GET TOP n RECOMMENDATION FOR USERS USING SURPRISE SVD\n",
    "user_id = 1\n",
    "n = 5\n",
    "\n",
    "user_predictions = []\n",
    "for movie_id in movies_df['movieId'].unique():\n",
    "    pred = algo.predict(str(user_id), str(movie_id))\n",
    "    user_predictions.append(pred)\n",
    "\n",
    "    \n",
    "    \n",
    "# SORT PREDICTION BY ESTIMATE RATINGS\n",
    "user_predictions.sort(key=lambda x: x.est, reverse=True)\n",
    "\n",
    "\n",
    "print(f\"Top {n} recommendations for User {user_id} using Surprise SVD:\")\n",
    "for pred in user_predictions[:n]:\n",
    "    movie_id = pred.iid\n",
    "    estimated_rating = pred.est\n",
    "    print(f\"Movie ID: {movie_id}, Estimated Rating: {estimated_rating}\")\n",
    "\n",
    "    \n",
    "    \n",
    "#DATA FOR XGBOOST MODEL\n",
    "X = ratings_df[['userId', 'movieId']]\n",
    "y = ratings_df['rating']\n",
    "\n",
    "# SPLIT DATA INTO TRAINING AND TESTING SET\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#MODEL\n",
    "xgb_model = XGBRegressor()\n",
    "\n",
    "# TRAIN THE MODEL\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "#PREDICTION ON TEST SET\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "# MODEL EVALUATE\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(f\"XGBoost RMSE: {rmse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7b0084",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee2c7e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
